{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as parquet\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.orc as orc\n",
    "import pyarrow.csv as csv\n",
    "import pyarrow as pa\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from filebench import constants as c\n",
    "\n",
    "def time_func(func, *args, **kwargs):\n",
    "    start = timer()\n",
    "    result = func(*args, **kwargs)\n",
    "    end = timer()\n",
    "    total_in_seconds = end - start\n",
    "    return result, total_in_seconds\n",
    "\n",
    "def write_file_from_df(df, filename, filetype):\n",
    "    if filetype == 'csv':\n",
    "        table = pa.Table.from_pandas(df)\n",
    "        csv.write_csv(table, filename)\n",
    "    elif filetype == 'parquet':\n",
    "        table = pa.Table.from_pandas(df)\n",
    "        parquet.write_table(table, filename, compression='none')\n",
    "    elif filetype == 'orc':\n",
    "        table = pa.Table.from_pandas(df)\n",
    "        orc.write_table(table, filename, compression='uncompressed')\n",
    "    elif filetype == 'feather':\n",
    "        feather.write_feather(df, filename, compression='uncompressed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv.read_csv(c.ORIGINAL_CSV_FILE).to_pandas()\n",
    "filenames = [c.PARQUET_FILE, c.ORC_FILE, c.FEATHER_FILE, c.CSV_FILE]\n",
    "filetypes = ['parquet', 'orc', 'feather', 'csv']\n",
    "\n",
    "all_results = []\n",
    "for i in range(10):\n",
    "    results = []\n",
    "    for filename, filetype in zip(filenames, filetypes):\n",
    "        filepath = Path(filename)\n",
    "        if filepath.is_file():\n",
    "            filepath.unlink()\n",
    "\n",
    "        _, time_in_seconds = time_func(\n",
    "            write_file_from_df,\n",
    "            df,\n",
    "            filename,\n",
    "            filetype\n",
    "        )\n",
    "\n",
    "        filesize_in_bytes = Path(filename).stat().st_size\n",
    "\n",
    "        all_results.append({\n",
    "            'test_number': i,\n",
    "            'func': write_file_from_df.__name__,\n",
    "            'filename': filename,\n",
    "            'filetype': filetype,\n",
    "            'time_in_seconds': time_in_seconds,\n",
    "            'filesize_in_bytes': filesize_in_bytes,\n",
    "            'filesize_in_MB': filesize_in_bytes / 1000000\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entire_file_to_df(filename, filetype):\n",
    "    \"\"\"Read entire file convert df and get shape\"\"\"\n",
    "    if filetype == 'parquet':\n",
    "        df = parquet.read_table(filename).to_pandas()\n",
    "    elif filetype == 'orc':\n",
    "        df = orc.read_table(filename).to_pandas()\n",
    "    elif filetype == 'feather':\n",
    "        df = feather.read_feather(filename)\n",
    "    elif filetype == 'csv':\n",
    "        df = csv.read_csv(filename).to_pandas()\n",
    "    \n",
    "    return df.shape\n",
    "\n",
    "\n",
    "def get_amount_participants(filename, filetype):\n",
    "    \"\"\"User_id is a column with high variety\"\"\"\n",
    "    if filetype == 'parquet':\n",
    "        df = parquet.read_table(filename, columns=['user_id']).to_pandas()\n",
    "    elif filetype == 'orc':\n",
    "        df = orc.read_table(filename, columns=['user_id']).to_pandas()\n",
    "    elif filetype == 'feather':\n",
    "        df = feather.read_feather(filename, columns=['user_id'])\n",
    "    elif filetype == 'csv':\n",
    "        df = csv.read_csv(filename).to_pandas()\n",
    "    \n",
    "    return pd.unique(df['user_id']).shape[0]\n",
    "\n",
    "\n",
    "def get_amount_colors_used(filename, filetype):\n",
    "    \"\"\"Pixel color is low variety 16 unique values\"\"\"\n",
    "    if filetype == 'parquet':\n",
    "        df = parquet.read_table(filename, columns=['pixel_color']).to_pandas()\n",
    "    elif filetype == 'orc':\n",
    "        df = orc.read_table(filename, columns=['pixel_color']).to_pandas()\n",
    "    elif filetype == 'feather':\n",
    "        df = feather.read_feather(filename, columns=['pixel_color'])\n",
    "    elif filetype == 'csv':\n",
    "        df = csv.read_csv(filename).to_pandas()\n",
    "    \n",
    "    return pd.unique(df['pixel_color']).shape[0]\n",
    "\n",
    "\n",
    "def get_number_of_rows(filename, filetype):        \n",
    "    \"\"\"Row count\"\"\"\n",
    "    if filetype == 'parquet':\n",
    "        num_rows = parquet.read_metadata(filename).num_rows\n",
    "    elif filetype == 'orc':\n",
    "        num_rows = orc.read_table(filename).num_rows\n",
    "    elif filetype == 'feather':\n",
    "        num_rows = feather.read_table(filename).num_rows\n",
    "    elif filetype == 'csv':\n",
    "        num_rows = csv.read_csv(filename).num_rows\n",
    "    \n",
    "    return num_rows"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1014a147ebe84edf89cc949d1474b378add343e44159593a1f5b609a8f202a90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
